{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from fastai.text import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = requests.get('https://www.gutenberg.org/files/36/36-0.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_iter = re.finditer('BOOK ONE', book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(1067, 1075), match='BOOK ONE'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(start_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting out some print lines here to shrink the notebook -- I did some exploration to figure out where the actual story began and ended (excluding table of contents, acknowledgements, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book[1067:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(1920, 1928), match='BOOK ONE'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(start_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book[1920:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = book[1920:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_iter = re.finditer(\"among the dead.\", book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(64109, 64124), match='among the dead '>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(end_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book[:64125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(345594, 345609), match='among the dead.'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(end_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book[:345609]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = book[:345609]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = re.sub(r'[\\r\\n]+', ' ', str(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [i.replace(',', '') for i in book.split('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOK ONE THE COMING OF THE MARTIANS I',\n",
       " ' THE EVE OF THE WAR',\n",
       " ' No one would have believed in the last years of the nineteenth century that this world was being watched keenly and closely by intelligences greater than manâ\\x80\\x99s and yet as mortal as his own; that as men busied themselves about their various concerns they were scrutinised and studied perhaps almost as narrowly as a man with a microscope might scrutinise the transient creatures that swarm and multiply in a drop of water',\n",
       " ' With infinite complacency men went to and fro over this globe about their little affairs serene in their assurance of their empire over matter',\n",
       " ' It is possible that the infusoria under the microscope do the same',\n",
       " ' No one gave a thought to the older worlds of space as sources of human danger or thought of them only to dismiss the idea of life upon them as impossible or improbable',\n",
       " ' It is curious to recall some of the mental habits of those departed days',\n",
       " ' At most terrestrial men fancied there might be other men upon Mars perhaps inferior to themselves and ready to welcome a missionary enterprise',\n",
       " ' Yet across the gulf of space minds that are to our minds as ours are to those of the beasts that perish intellects vast and cool and unsympathetic regarded this earth with envious eyes and slowly and surely drew their plans against us',\n",
       " ' And early in the twentieth century came the great disillusionment']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm book_text.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('book_text.csv', 'a+') as file:\n",
    "    for sentence in tokens:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ONE THE COMING OF THE MARTIANS I\n",
      "\n",
      " THE EVE OF THE WAR\n",
      "\n",
      " No one would have believed in the last years of the nineteenth century that this world was being watched keenly and closely by intelligences greater than manâs and yet as mortal as his own; that as men busied themselves about their various concerns they were scrutinised and studied perhaps almost as narrowly as a man with a microscope might scrutinise the transient creatures that swarm and multiply in a drop of water\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('book_text.csv') as file:\n",
    "    lines = file.readlines()[:5]\n",
    "print(lines[0])\n",
    "print(lines[1])\n",
    "print(lines[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' And looking across space with instruments and intelligences such as we have scarcely dreamed of they see at its nearest distance only 35000000 of miles sunward of them a morning star of hope our own warmer planet green with vegetation and grey with water with a cloudy atmosphere eloquent of fertility with glimpses through its drifting cloud wisps of broad stretches of populous country and narrow navy-crowded seas'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('book_text.csv').iloc[20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextLMDataBunch.from_csv('.', 'book_text.csv', text_cols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (2434 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj the xxmaj shepperton guns spoke this time xxunk,xxbos xxmaj but i believed in him sufficiently to work with him all that morning until past midday at his digging,xxbos xxmaj he wanted the slit which permitted only one of us to xxunk through ; and so i had to xxunk watching them for a time while he xxunk that privilege,xxbos xxmaj on me and mine be the xxunk laid,xxbos âit would be curious to know how they live on another planet ; we might learn a thing or two\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (609 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj perhaps they also prayed xxunk to xxmaj god,xxbos xxmaj even the birds were xxunk and as we hurried along i and the artilleryman talked in xxunk and looked now and again over our shoulders,xxbos a xxunk xxunk runs towards the foot of xxmaj maybury xxmaj hill and down this we xxunk,xxbos â xxmaj on that last xxunk their xxunk - writer xxunk very xxunk,xxbos xxmaj for a time i believed that xxunk had been swept out of existence and that i stood there alone the last man left alive\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos xxmaj the xxmaj shepperton guns spoke this time xxunk, EmptyLabel )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5,  31,  14, 888,  15,  60, 889,  13, 305,  20,  60,  42,  17, 245, 181, 283, 692,  22,  37, 620])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[1][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    5,  120,    9, 1021,   25,    0,   10,   21,   36,  469,  125,   14,   10,    9,  273,  653,   15,\n",
       "          0,   10,  179,   87,   10,   84,   62,   86, 2235])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds[1][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 70])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  24, 2063,   18,   13,   12, 1531, 1532,   11,  373,  128,   10,  891,\n",
       "         2064,   38,   11,    9,  256, 2065, 1242, 2066,  556,   38,   11,   12,\n",
       "          467,    2,    5,  183,    9,  168,   16,    0,   10,    9, 2067,  321,\n",
       "         1044,  233,  780,  246,    2,    0,  557,  129,   88, 1045,    2,    5,\n",
       "            9,  137,  198,    9,  247,   27,  399,   16, 2068,   20,   58,  219,\n",
       "           89,  170,   15,   12,  234,   27, 1533,  289,  267,   22]),\n",
       " tensor([2063,   18,   13,   12, 1531, 1532,   11,  373,  128,   10,  891, 2064,\n",
       "           38,   11,    9,  256, 2065, 1242, 2066,  556,   38,   11,   12,  467,\n",
       "            2,    5,  183,    9,  168,   16,    0,   10,    9, 2067,  321, 1044,\n",
       "          233,  780,  246,    2,    0,  557,  129,   88, 1045,    2,    5,    9,\n",
       "          137,  198,    9,  247,   27,  399,   16, 2068,   20,   58,  219,   89,\n",
       "          170,   15,   12,  234,   27, 1533,  289,  267,   22,   75]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3088"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nv = len(data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nh = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3088, 64, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv, nh, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicLanguageModel(nn.Module):\n",
    "     \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh) \n",
    "        self.h_h = nn.Linear(nh, nh)\n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = nn.BatchNorm1d(nh)\n",
    "        self.reset()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = []\n",
    "        h = self.h\n",
    "        for i in range(x.shape[1]):\n",
    "            h = h + self.i_h(x[:,i]) \n",
    "            h = F.relu(self.h_h(h))\n",
    "            res.append(self.bn(h))\n",
    "        self.h = h.detach()\n",
    "        res_stacked = torch.stack(res, dim=1)\n",
    "        out = self.h_o(res_stacked)\n",
    "        return (out, res, res)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.h = torch.zeros(nh, nh).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = BasicLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLanguageModel(\n",
       "  (i_h): Embedding(3088, 64)\n",
       "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (h_o): Linear(in_features=64, out_features=3088, bias=True)\n",
       "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = LanguageLearner(data, model=mdl, metrics=accuracy)\n",
    "# learn = Learner(data, model=mdl, metrics=accuracy)\n",
    "# learn = language_model_learner(data, arch=AWD_LSTM, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:18 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>5.285446</th>\n",
       "    <th>4.950697</th>\n",
       "    <th>0.152288</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>5.115359</th>\n",
       "    <th>4.808184</th>\n",
       "    <th>0.183929</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>4.967049</th>\n",
       "    <th>4.701544</th>\n",
       "    <th>0.192188</th>\n",
       "    <th>00:01</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>4.834863</th>\n",
       "    <th>4.640527</th>\n",
       "    <th>0.198828</th>\n",
       "    <th>00:01</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>4.718391</th>\n",
       "    <th>4.635948</th>\n",
       "    <th>0.203348</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>4.610754</th>\n",
       "    <th>4.615658</th>\n",
       "    <th>0.201339</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>4.515334</th>\n",
       "    <th>4.611588</th>\n",
       "    <th>0.208147</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>4.424106</th>\n",
       "    <th>4.664527</th>\n",
       "    <th>0.206696</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>4.330434</th>\n",
       "    <th>4.673954</th>\n",
       "    <th>0.205915</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>4.242741</th>\n",
       "    <th>4.713938</th>\n",
       "    <th>0.198828</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>4.158474</th>\n",
       "    <th>4.776047</th>\n",
       "    <th>0.199442</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>4.092573</th>\n",
       "    <th>4.736320</th>\n",
       "    <th>0.205022</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>4.015049</th>\n",
       "    <th>4.749926</th>\n",
       "    <th>0.204129</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>3.929154</th>\n",
       "    <th>4.827871</th>\n",
       "    <th>0.201563</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>3.847466</th>\n",
       "    <th>4.896731</th>\n",
       "    <th>0.199163</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>3.774626</th>\n",
       "    <th>4.899357</th>\n",
       "    <th>0.197545</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>3.713506</th>\n",
       "    <th>4.922647</th>\n",
       "    <th>0.197600</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>3.667609</th>\n",
       "    <th>4.945030</th>\n",
       "    <th>0.194587</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>3.615727</th>\n",
       "    <th>4.917067</th>\n",
       "    <th>0.199219</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>3.572838</th>\n",
       "    <th>4.969650</th>\n",
       "    <th>0.200614</th>\n",
       "    <th>00:00</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "learn.fit(20, lr=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the darkness  and then it would be the that that are the three bulk overtaken him and stood about me a full'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"In the darkness \", n_words=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
